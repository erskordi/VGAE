{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.datasets import citation\n",
    "from spektral.layers import GraphConv # for Graph Convolutional Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": [
    "A, X, y, train_mask, val_mask, test_mask = citation.load_data('cora')\n",
    "# A: adjacency matrix == shape(N,N)\n",
    "# X: node features == shape(N,F)\n",
    "# y: labels == shape(N,n_classes)\n",
    "# train_mask, val_mask, test_mask: boolean, shows which nodes belong to training, validation, testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = A.shape[0]\n",
    "F = X.shape[-1]\n",
    "n_classes = y.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GNN\n",
    "\n",
    "X_in = Input(shape=(F,))\n",
    "A_in = Input(shape=(N,), sparse=True)\n",
    "\n",
    "X_1 = GraphConv(16, 'relu')([X_in, A_in])\n",
    "X_1 = Dropout(.5)(X_1)\n",
    "X_2 = GraphConv(n_classes, 'softmax')([X_1, A_in])\n",
    "\n",
    "model = Model(inputs=[X_in, A_in], outputs=X_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to notice at this point is how we defined the Input layers of our model. Because the \"elements\" of our dataset are the nodes themselves, we are telling Keras to consider each node as a separate sample so that the batch axis is implicitly defined as None.\n",
    "In other words, a sample of the node attributes will be a vector of shape (F, ) and a sample of the adjacency matrix will be one row of shape (N, ).\n",
    "\n",
    "# Training GCN\n",
    "\n",
    "When training GCN, we have to pre-process the adjacency matrix to 1) add self-loops and 2) scale the weights of a node's connections according to its degree.\n",
    "\n",
    "Some layers in Spektral require a different type of pre-processing in order to work correctly, and some work out-of-the-box on the binary A. The pre-processing required by each layer is available as a static class method preprocess()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = GraphConv.preprocess(A).astype('f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1433)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2708)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv (GraphConv)          (None, 16)           22944       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16)           0           graph_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_1 (GraphConv)        (None, 7)            119         dropout[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,063\n",
      "Trainable params: 23,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             weighted_metrics=['acc']) # weighted metrics instead of metrics due to particular semi-supervised problem\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " <2708x2708 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 13264 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prep data\n",
    "X = X.toarray()\n",
    "A = A.astype('f4')\n",
    "validation_data = ([X, A], y, val_mask)\n",
    "\n",
    "X, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2708, 1433),\n",
       " (2708, 2708),\n",
       " ([array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       "   <2708x2708 sparse matrix of type '<class 'numpy.float32'>'\n",
       "   \twith 13264 stored elements in Compressed Sparse Row format>],\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 1, 0, 0],\n",
       "         [0, 0, 0, ..., 1, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int32),\n",
       "  array([False, False, False, ..., False, False, False])))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, A.shape, validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have set batch_size=N and shuffle=False. This is because the default behaviour of Keras is to split the data into batches of 32 and shuffle the samples at each epoch. However, shuffling the adjacency matrix along one axis and not the other means that row i will represent a different node than column i.\n",
    "At the same time, if we split the graph into batches we may end up in a situation where we need to use a node attribute that is not part of the batch. The only solution is to take all the node features at the same time, hence batch_size=N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1006 - acc: 0.2143 - val_loss: 0.3592 - val_acc: 0.2000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1005 - acc: 0.2214 - val_loss: 0.3591 - val_acc: 0.2080\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1005 - acc: 0.2929 - val_loss: 0.3591 - val_acc: 0.2200\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1005 - acc: 0.3143 - val_loss: 0.3590 - val_acc: 0.2420\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1005 - acc: 0.2643 - val_loss: 0.3589 - val_acc: 0.2600\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1004 - acc: 0.3357 - val_loss: 0.3588 - val_acc: 0.3000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1004 - acc: 0.3714 - val_loss: 0.3587 - val_acc: 0.3420\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1003 - acc: 0.3429 - val_loss: 0.3586 - val_acc: 0.3840\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1003 - acc: 0.4286 - val_loss: 0.3585 - val_acc: 0.4000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1002 - acc: 0.4929 - val_loss: 0.3585 - val_acc: 0.4160\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1003 - acc: 0.4143 - val_loss: 0.3584 - val_acc: 0.4340\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1002 - acc: 0.4571 - val_loss: 0.3583 - val_acc: 0.4580\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1001 - acc: 0.4786 - val_loss: 0.3582 - val_acc: 0.4640\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1001 - acc: 0.4143 - val_loss: 0.3581 - val_acc: 0.4620\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1001 - acc: 0.4500 - val_loss: 0.3580 - val_acc: 0.4780\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1000 - acc: 0.5286 - val_loss: 0.3579 - val_acc: 0.4860\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1000 - acc: 0.4929 - val_loss: 0.3578 - val_acc: 0.4840\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0999 - acc: 0.5286 - val_loss: 0.3577 - val_acc: 0.4940\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0999 - acc: 0.4643 - val_loss: 0.3577 - val_acc: 0.5100\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0998 - acc: 0.5571 - val_loss: 0.3576 - val_acc: 0.5080\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0998 - acc: 0.5786 - val_loss: 0.3575 - val_acc: 0.5120\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0997 - acc: 0.6071 - val_loss: 0.3574 - val_acc: 0.5120\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0997 - acc: 0.5786 - val_loss: 0.3573 - val_acc: 0.5360\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0995 - acc: 0.6214 - val_loss: 0.3572 - val_acc: 0.5400\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0994 - acc: 0.6214 - val_loss: 0.3571 - val_acc: 0.5460\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0994 - acc: 0.6929 - val_loss: 0.3570 - val_acc: 0.5540\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0993 - acc: 0.6643 - val_loss: 0.3569 - val_acc: 0.5580\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0993 - acc: 0.7071 - val_loss: 0.3568 - val_acc: 0.5680\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0992 - acc: 0.6357 - val_loss: 0.3566 - val_acc: 0.5700\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0992 - acc: 0.6786 - val_loss: 0.3565 - val_acc: 0.5760\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0992 - acc: 0.6429 - val_loss: 0.3564 - val_acc: 0.5820\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0989 - acc: 0.7214 - val_loss: 0.3563 - val_acc: 0.5880\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0990 - acc: 0.7214 - val_loss: 0.3561 - val_acc: 0.5960\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0989 - acc: 0.7214 - val_loss: 0.3560 - val_acc: 0.5940\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0986 - acc: 0.7143 - val_loss: 0.3558 - val_acc: 0.6060\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0988 - acc: 0.7143 - val_loss: 0.3557 - val_acc: 0.6160\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0987 - acc: 0.7714 - val_loss: 0.3555 - val_acc: 0.6240\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0985 - acc: 0.6929 - val_loss: 0.3553 - val_acc: 0.6340\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0985 - acc: 0.7500 - val_loss: 0.3552 - val_acc: 0.6440\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0983 - acc: 0.7500 - val_loss: 0.3550 - val_acc: 0.6460\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0983 - acc: 0.7714 - val_loss: 0.3548 - val_acc: 0.6480\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0983 - acc: 0.7429 - val_loss: 0.3547 - val_acc: 0.6660\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0982 - acc: 0.7500 - val_loss: 0.3545 - val_acc: 0.6700\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0981 - acc: 0.7357 - val_loss: 0.3544 - val_acc: 0.6780\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0979 - acc: 0.8000 - val_loss: 0.3542 - val_acc: 0.6760\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0979 - acc: 0.7357 - val_loss: 0.3541 - val_acc: 0.6740\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0978 - acc: 0.8000 - val_loss: 0.3539 - val_acc: 0.6680\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0977 - acc: 0.7714 - val_loss: 0.3537 - val_acc: 0.6680\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0979 - acc: 0.7071 - val_loss: 0.3536 - val_acc: 0.6720\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0975 - acc: 0.7714 - val_loss: 0.3534 - val_acc: 0.6760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1454edda0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit([X, A], y,\n",
    "         sample_weight=train_mask,\n",
    "         validation_data=validation_data,\n",
    "         batch_size=N,\n",
    "         shuffle=False,\n",
    "         epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2\n",
       "0   True  False  False\n",
       "1   True  False  False\n",
       "2   True  False  False\n",
       "3   True  False  False\n",
       "4   True  False  False\n",
       "5   True  False  False\n",
       "6   True  False  False\n",
       "7   True  False  False\n",
       "8   True  False  False\n",
       "9   True  False  False\n",
       "10  True  False  False\n",
       "11  True  False  False\n",
       "12  True  False  False\n",
       "13  True  False  False\n",
       "14  True  False  False\n",
       "15  True  False  False\n",
       "16  True  False  False\n",
       "17  True  False  False\n",
       "18  True  False  False\n",
       "19  True  False  False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([train_mask, val_mask, test_mask]).T.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 733us/step - loss: 0.7066 - acc: 0.6810\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = model.evaluate([X, A],\n",
    "                              y,\n",
    "                              sample_weight=test_mask,\n",
    "                              batch_size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Test loss: 0.7065826654434204\n",
      "Test accuracy: 0.6809999942779541\n"
     ]
    }
   ],
   "source": [
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
